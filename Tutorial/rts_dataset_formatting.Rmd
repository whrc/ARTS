---
title: "Metadata Formatting for the ARTS Data Set"
author: "Heidi Rodenhizer"
date: "January 2024"
output: html_document
---

# Set-Up

```{r}
library(R.utils)
library(reticulate)
library(sf)
library(tidyverse)
source("../src/ARTS/dataformatting.R")
```

## User-Defined Input

Would you like to run this as a demo with the mock data set? Provide 'TRUE' (mock data demo) or 'FALSE' (actual data processing of a new contribution):

```{r}
demo = TRUE
```

Before starting, copy your new RTS dataset (can be a shapefile or a geojson) into a directory called "input_data" within the directory in which you would like to work. If you do not change any code in the following code chunk, the default directory will be the directory up one level from the location of this script.

Default file structure:
    
    > ARTS (default working directory)
        > ARTS_main_dataset
        > img
        > **input_data**
        > src
        > Tutorial

Provide the location of the directory in which you are working:

```{r}
# If you have followed all of the directions as in the README, this should work without edits, but you can always edit it if you did things differently
base_dir = '..'

print(paste('Your base directory is', getAbsolutePath(base_dir)))
```

Provide the file name of the data:

```{r}
# set this - if demo == TRUE, what this is set to doesn't matter
your_file = 'new_data.geojson'  # set this
dataset_version = 'v.1.0.0' # set this to the most recent version

# leave everything else in this chunk alone
if (demo) {
  
  # RTS data set to be processed
  your_rts_dataset_file = 'rts_dataset_test_polygons_new.geojson'
  your_rts_dataset_filepath = paste(
    base_dir,
    'Tutorial/mock_dataset/input_data',
    your_rts_dataset_file,
    sep = '/'
  )
  
  # ARTS main dataset to be appended
  ARTS_main_dataset_filepath = paste(
    base_dir,
    'Tutorial/mock_dataset/input_data/rts_dataset_test_polygons_current.geojson',
    sep = '/'
  )
  
} else {
  
  # RTS data set to be processed
  your_rts_dataset_file = your_file
  your_rts_dataset_filepath = paste(
    base_dir,
    'input_data',
    your_rts_dataset_file,
    sep = '/'
  )
  
  # ARTS main dataset to be appended
  ARTS_main_dataset_filepath = paste(
    base_dir,
    'ARTS_main_dataset',
    dataset_version,
    'ARTS_main_dataset.geojson',
    sep = '/'
  )
  
}

# Metadata Description File
metadata_filepath = paste(
  base_dir,
  'Metadata_Format_Summary.csv',
  sep = '/'
  )
```

Provide the names of any metadata fields in your new file that are not already in the official RTS Data Set (please check the list to ensure that the field has not been included previously) that you would like to be included in the compiled data set:

```{r}
# Provide new metatdata fields as a list of the character column names. If there are no new fields, leave the code assigning an empty vector.
# If your new file is a shapefile, also provide a list of the abbreviated names

# Example:
# new_fields = c('CustomColumn1', 'CustomColumn2')

# Shapefile example:
# new_fields_abbreviated = c('CstmCl1', 'CstmCl2')
# new_fields = c('CustomColumn1' = 'CstmCl1', 'CustomColumn2' = 'CstmCl2')

new_fields = c()
new_fields_abbreviated = c()
```

Have you already created RTS centroid columns, or would you like them to be created within this script? Provide either TRUE, if the columns do not exist yet, or FALSE, if you have already created them:

```{r}
# Example: 
# calculate_centroid = FALSE
calculate_centroid = FALSE
```

Would you like your formatted new data to be output in its own file (in which case you will email the file of new features to us to merge with the compiled data set) or appended the compiled dataset (in which case you will commit your updated file to your forked github repository and create a pull request to add the file to the official github repository). Your decision here should mostly be based on your comfort with github. If you have no idea what the second half of that sentence means, please opt for the separate file and email it to us.

```{r}
# Example
# separate_file = TRUE
separate_file = FALSE
```


# Import Metadata Description File

```{r}
metadata_format_summary = read_csv(metadata_filepath)

required_fields = metadata_format_summary |>
  filter(Required == 'True') |>
  pull(FieldName)

generated_fields = metadata_format_summary |>
  filter(Required == 'Generated') |>
  pull(FieldName)

optional_fields = metadata_format_summary |>
  filter(Required == 'False') |>
  pull(FieldName)

all_fields = c(required_fields, 
                generated_fields, 
                optional_fields, 
                new_fields)
```


# Load the Main ARTS Data Set

If you get the error 'Error in `all_of()`: ! Can't subset columns that don't exist. ✖ Column `{required_column}` doesn't exist.', check to make sure that all of the required columns (except UID, and optionally CentroidLat and CentroidLon) and new columns are present and named correctly in your shapefile of new RTS features.

```{r}
ARTS_main_dataset = read_sf(ARTS_main_dataset_filepath) |>
  select(all_of(c(!!!required_fields)),
         any_of(c(!!!generated_fields, !!!optional_fields)))
```

# Load Your New RTS Data Set

```{r}
new_dataset = preprocessing(
  your_rts_dataset_filepath,
  required_fields,
  generated_fields,
  optional_fields,
  new_fields,
  calculate_centroid
)
```


# Check Metadata Format of New Data

```{r}
run_formatting_checks(new_dataset)
```


# Generate UIDs

Set seed for UID generation (R) by concatenating all required metadata columns (except UID) into a single string
```{r}
new_dataset = seed_gen(new_dataset)

new_seeds = new_dataset |>
  pull(seed)
```

Generate UIDs (Python via reticulate package)
```{python}
import uuid
```

```{python}
new_uids = [str(uuid.uuid5(uuid.NAMESPACE_DNS, name = seed)) for seed in r.new_seeds]
r.new_uids = new_uids
```

Add UIDs to New RTS Data (R)
```{r}
new_dataset = new_dataset |>
  mutate(UID = new_uids,
         .after = seed)
```

# Check for Intersections with RTS Data Set

Find intersecting RTS polygons from the official RTS data set and retrieve their UIDs. Create empty columns to manually classify the repeated polygons.
```{r}
if (demo) {
  intersections_output_filepath = paste(
    base_dir,
    'Tutorial/mock_dataset/output',
    paste0(str_split(your_rts_dataset_file, '\\.')[[1]][1], 
           '_overlapping_polygons.geojson'
           ),
    sep = '/'
  )
} else {
  intersections_output_filepath = paste(
    base_dir,
    'output',
    paste0(str_split(your_rts_dataset_file, '\\.')[[1]][1], 
           '_overlapping_polygons.geojson'
           ),
    sep = '/'
  )
}

new_dataset = check_intersections(
  new_dataset,
  ARTS_main_dataset,
  intersections_output_filepath,
  demo
)
```

At this point, you will need to manually check all polygons with intersections against the polygons in the official RTS data set and polygons with self intersections against themselves in your preferred GIS software and save the output to `r paste0(str_split(your_rts_dataset_file, '\\.')[[1]][1], '_overlapping_polygons_edited.geojson')` (press Ctrl+Enter while cursor is in the preceding in-line code chunk to see the actual file name, rather than the code to produce the file name).  When possible/necessary, try to find imagery that matches the date of the intersecting polygons - this may require contacting the lab that did the original delineation.

Your job is to inspect each of the previously published polygons listed in the 'Intersections' column compared to the new RTS feature and manually copy and paste the UIDs from the 'Intersections' column into the 'RepeatRTS', 'StabilizedRTS', 'NewRTS', 'MergedRTS', 'AccidentalOverlap', or 'UnknownRelationship' based on the relationship between the two polygons. Similarly, you need to inspect each of the polygons listed in the 'SelfIntersections' column and copy and paste the UIDs from the 'SelfIntersections' column into the 'RepeatRTS', 'StabilizedRTS', 'NewRTS', 'MergedRTS', 'AccidentalOverlap', or 'UnknownRelationship' based on the relationship between the two polygons.

There may be multiple UIDs in the ‘Intersections’ and ‘SelfIntersections’ columns. When multiple UIDs are present, they are separated by a comma (no spaces). When copying and pasting multiple UIDs, ensure that each UID is pasted into the correct column (they will not always have the same relationship to the polygon in that row) and that no leading or trailing commas are present in the column(s) in which the UIDs were pasted.

- Paste the UID into the RepeatRTS column when the RTS feature in the current row is the same RTS feature as the RTS feature in the 'Intersections' or 'SelfIntersections' column, but was delineated at a different point in time, by a different lab at the same point in time, or from different imagery at the same point in time. The RTS feature is the same when it was the result of the same RTS initiation event.

- Paste the UID into the NewRTS column when the RTS feature in the 'Intersections' or 'SelfIntersections' column is a new RTS feature which formed on top of the RTS feature in the current row.

- Paste the UID into the StabilizedRTS column when the RTS feature in the 'Intersections' or 'SelfIntersections' column is a stabilized RTS scar as of the date of the imagery used in the new RTS delineations.

- Paste the UID into the MergedRTS column when multiple RTS features in the 'Intersections' or 'SelfIntersections' column merged to form the new RTS feature.

- Paste the UID into the AccidentalOverlap column when inaccuracies in delineation of separate RTS features lead to overlap (e.g. features that are very close to each other and the polygons barely overlap).

- If you are unable to determine the relationship based on an inspection of the original imagery and the available information, you can copy the UID into the UnknownRelationship column. NOTE: This should be a last resort used in rare occasions (e.g. the researcher who delineated the feature cannot be contacted and insufficient information was recorded to make a reasonably confident decision), as it will limit the utility of the row of data to researchers.  

When this is done, each of the UIDs in the 'Intersections' and 'SelfIntersections' columns should have been copied into one (and only one) of the 'RepeatRTS', 'StabilizedRTS', 'NewRTS', 'MergedRTS', 'AccidentalOverlap', or 'UnknownRelationship' columns.


# Load Manually Edited File and Join to New Data

Add the 'RepeatRTS', 'StabilizedRTS', 'NewRTS', 'MergedRTS', 'AccidentalOverlap', or 'UnknownRelationship' columns that you just edited back into `new_dataset`.

```{r}
if (demo) {
  edited_filepath = paste(
    base_dir,
    'Tutorial/mock_dataset/output',
    paste0(
      str_split(your_rts_dataset_file, '\\.')[[1]][1], 
      '_overlapping_polygons_edited.geojson'
    ), 
    sep = '/'
  )
} else {
  edited_filepath = paste(
    base_dir,
    'output',
    paste0(
      str_split(your_rts_dataset_file, '\\.')[[1]][1], 
      '_overlapping_polygons_edited.geojson'
    ), 
    sep = '/'
  )
}

merged_data = merge_data(new_dataset, edited_filepath)
```

# Check Completeness of Intersection Information

```{r}
check_intersection_info(merged_data, your_rts_dataset_file, base_dir)
```


# Final Column Selection

```{r}
formatted_data = merged_data |>
  add_empty_columns(optional_fields) |>
  select(all_of(all_fields))
```

# Save Formatted File as a Shapefile

```{r}
new_increment = dataset_version |>
  str_split_i('\\.', i = 2) |>
  str_split_i('-', i = 1) |>
  as.numeric() + 1

new_version = str_flatten(
  c(str_split(dataset_version, '\\.')[[1]][1], 
    new_increment,
    '0',
    '0'
    ), 
  '.')

updated_ARTS_filepath = paste(
    base_dir,
    'ARTS_main_dataset',
    new_version,
    sep = '/'
  )

output(formatted_data,
       ARTS_main_dataset,
       new_fields,
       all_fields,
       base_dir,
       your_rts_dataset_file,
       updated_ARTS_filepath,
       separate_file,
       demo)
```

Now you are ready to submit `r ifelse(separate_file == TRUE, paste0(str_split(your_rts_dataset_file, '\\.')[[1]][1], '_formatted.geojson'), rts_file)`!